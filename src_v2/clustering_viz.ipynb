{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - AE model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold.t_sne import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "homedir = os.path.expanduser('~')\n",
    "prjdir = 'Desktop/ehr-stratification'\n",
    "datadir = 'data'\n",
    "outdir = path.join(homedir, prjdir, datadir, 'mixed')\n",
    "expdir = path.join(homedir, prjdir, datadir, 'experiments/mixed-2019-02-21-17-39-46')\n",
    "\n",
    "# sub-sampling\n",
    "n_samples = 5000\n",
    "\n",
    "# read encoded vectors file and ordered medical record numbers\n",
    "with open(path.join(expdir, 'mrns.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    mrns = [r[0] for r in rd]\n",
    "\n",
    "with open(path.join(expdir, 'encoded_vect.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    encoded = [list(map(float, r)) for r in rd]\n",
    "\n",
    "# sub-sample the collection\n",
    "if n_samples is not None:\n",
    "    idx = [i for i in range(len(mrns))]\n",
    "    random.shuffle(idx)\n",
    "    idx = idx[:n_samples]\n",
    "    mrn_tmp = [mrns[i] for i in idx]\n",
    "    enc_tmp = [encoded[i] for i in idx]\n",
    "    mrns = mrn_tmp\n",
    "    encoded = enc_tmp\n",
    "set_mrns = set(mrns)\n",
    "    \n",
    "# read the vocabulary\n",
    "with open(path.join(outdir, 'cohort-new_vocab.csv')) as f:    \n",
    "    rd = csv.reader(f)\n",
    "    next(rd)\n",
    "    vocab = {r[1]: r[0] for r in rd}\n",
    "len_vocab = len(vocab)\n",
    "\n",
    "# read raw data\n",
    "with open(path.join(outdir, 'cohort-new_ehr.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    raw_ehr = {}\n",
    "    for r in rd:\n",
    "        if r[0] in set_mrns:\n",
    "            raw_ehr.setdefault(r[0], list()).extend(list(map(int, r[1::])))\n",
    "\n",
    "# raw data (scaled) counts\n",
    "scaler = StandardScaler()\n",
    "data = raw_ehr.values()\n",
    "raw_data = np.zeros((len(data), len_vocab))\n",
    "for idx, token_list in enumerate(data):\n",
    "    for t in token_list:\n",
    "        raw_data[idx, t - 1] += 1\n",
    "\n",
    "raw_data_scaled = scaler.fit_transform(raw_data)\n",
    "\n",
    "# get the list of diagnosed diseases associated with mrns\n",
    "with open(path.join(outdir, 'cohort-mrn_diseases.csv')) as f:\n",
    "    rd = csv.reader(f)\n",
    "    mrn_disease = {r[0]: r[1::] for r in rd if r[0] in set_mrns}\n",
    "\n",
    "# evaluate potential disease classes\n",
    "\n",
    "# (1) first diagnosis\n",
    "gt_disease = {m: mrn_disease[m][0] for m in mrn_disease}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`svd_tfidf():` returns the SVD matrix of the TFIDF matrix of the raw ehr data;\n",
    "\n",
    ">`silhouette_analysis():` hierarchical clustering on input data maximizing the Silhouette Index\n",
    "\n",
    ">`single_plot():` one plot of all the clusters\n",
    "\n",
    ">`nonoveralp_plot():` N different plots, one per cluster, with N = no. of clusters\n",
    "\n",
    "> `outer_clustering_analysis():` external validation of clustering (entropy and Purity scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze clustering using silhouette scores\n",
    "def silhouette_analysis(data,\n",
    "                        min_clu=2,\n",
    "                        max_clu=10,\n",
    "                        affinity_clu='euclidean'):\n",
    "    # bound analysis range\n",
    "    if min_clu < 2:\n",
    "        min_clu = 2\n",
    "\n",
    "    # run analysis for every clustering size\n",
    "    best_silh = 0\n",
    "    silh_scores = []\n",
    "    for n in range(min_clu, max_clu, 1):\n",
    "        hclu = AgglomerativeClustering(n_clusters=n,\n",
    "                                       linkage='ward',\n",
    "                                       affinity=affinity_clu)\n",
    "        lbl = hclu.fit_predict(data).tolist()\n",
    "        silh = silhouette_score(data, lbl)\n",
    "        if silh < 0:\n",
    "            break\n",
    "        print(' -- {0}: {1:.3f}'.format(n, silh))\n",
    "        silh_scores.append(silh)\n",
    "        if silh > best_silh:\n",
    "            best_silh = silh\n",
    "            n_clu = n\n",
    "            label = lbl\n",
    "    try:\n",
    "        print('No. of clusters: {0} -- Silhouette Score: {1:.3f}\\n'.format(\n",
    "            n_clu, best_silh))\n",
    "\n",
    "    except UnboundLocalError:\n",
    "        hclu = AgglomerativeClustering(n_clusters=min_clu,\n",
    "                                       linkage='complete',\n",
    "                                       affinity=affinity_clu)\n",
    "        n_clu = min_clu\n",
    "        label = hclu.fit_predict(data).tolist()\n",
    "        print('No. of Clusters: {0} -- Silhouette Score: {1:.3f}\\n'.format(\n",
    "            n_clu, best_silh))\n",
    "\n",
    "    return (n_clu, label, silh_scores)\n",
    "\n",
    "\n",
    "# SVD matrix of the TFIDF matrix of the raw ehr data\n",
    "def svd_tfidf(data, len_vocab, n_dimensions=200):\n",
    "    # apply tf-idf\n",
    "    tfidf = TfidfTransformer()\n",
    "    tfidf_mtx = tfidf.fit_transform(data)\n",
    "\n",
    "    # reduce size of the matrix\n",
    "    svd = TruncatedSVD(n_components=n_dimensions)\n",
    "    svd_mtx = svd.fit_transform(tfidf_mtx)\n",
    "\n",
    "    return svd_mtx\n",
    "\n",
    "\n",
    "# one plot with all the clusters\n",
    "def single_plot(data, mrn_disease, colors):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for cl in set(mrn_disease):\n",
    "        x = [d[0] for j, d in enumerate(data) if mrn_disease[j] == cl]\n",
    "        y = [d[1] for j, d in enumerate(data) if mrn_disease[j] == cl]\n",
    "        cols = [c for j, c in enumerate(colors) if mrn_disease[j] == cl]\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.scatter(x, y, c=cols, label=cl)\n",
    "    plt.legend()\n",
    " \n",
    "    \n",
    "# non-overlapping plots, one per cluster\n",
    "def nonoverlap_plot(data, mrn_disease, colors):\n",
    "    fig, ax = plt.subplots(len(set(mrn_disease)), 1, figsize=(20, 10*len(set(mrn_disease))))\n",
    "    for idx, cl in enumerate(set(mrn_disease)):\n",
    "        x = [d[0] for j, d in enumerate(data) if mrn_disease[j] == cl]\n",
    "        y = [d[1] for j, d in enumerate(data) if mrn_disease[j] == cl]\n",
    "        cols = [c for j, c in enumerate(colors) if mrn_disease[j] == cl]\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        ax[idx].scatter(x, y, c=cols, label=cl)\n",
    "        ax[idx].legend()\n",
    "\n",
    "        \n",
    "# external clustering analysis\n",
    "def outer_clustering_analysis(data, gt_clu, affinity_clu='euclidean'):\n",
    "    label_clu = sorted(set(gt_clu))\n",
    "\n",
    "    # format clustering ground truth\n",
    "    didx = {d: i for i, d in enumerate(label_clu)}\n",
    "    idxd = {i:d for d, i in didx.items()}\n",
    "    gt = [didx[d] for d in gt_clu]\n",
    "\n",
    "    # validate cluster number\n",
    "    if len(label_clu) == 1:\n",
    "        n_clu = 3\n",
    "    else:\n",
    "        n_clu = len(label_clu)\n",
    "\n",
    "    # run clustering\n",
    "    hclust = AgglomerativeClustering(n_clusters=n_clu,\n",
    "                                     linkage='ward',\n",
    "                                     affinity=affinity_clu)\n",
    "    clusters = hclust.fit_predict(data).tolist()\n",
    "\n",
    "    # count cluster occurrences\n",
    "    cnt_clu = [0] * n_clu\n",
    "    for c in clusters:\n",
    "        cnt_clu[c] += 1\n",
    "    class_clu = [[0] * n_clu for _ in range(len(label_clu))]\n",
    "    for i, gi in enumerate(gt):\n",
    "        class_clu[gi][clusters[i]] += 1\n",
    "\n",
    "    # compute entropy and purity\n",
    "    entropy = 0\n",
    "    purity = 0\n",
    "    for j in range(0, max(clusters) + 1):\n",
    "        en = 0\n",
    "        pu = []\n",
    "        for i in range(0, max(gt) + 1):\n",
    "            pij = class_clu[i][j] / cnt_clu[j]\n",
    "            pu.append(pij)\n",
    "            if pij != 0:\n",
    "                en += -(pij * np.log2(pij))\n",
    "        max_pu = max(pu)\n",
    "        ds_max = []\n",
    "        for idx, p in enumerate(pu):\n",
    "            if p == max_pu:\n",
    "                ds_max.append(idxd[idx])\n",
    "        print(\n",
    "            'Cluster: {0} -- '\n",
    "            'Entropy: {1:.3f}, '\n",
    "            'Purity: {2:.3f}'.format(j, en, max_pu))\n",
    "        for d in ds_max:\n",
    "            print(\"max(P) in cluster disease {0}\".format(d))\n",
    "        cweight = cnt_clu[j] / len(gt)\n",
    "        entropy += cweight * en\n",
    "        purity += cweight * max_pu\n",
    "\n",
    "    print('Average Entropy: {0:.2f}'.format(entropy))\n",
    "    print('Average Purity: {0:.2f}'.format(purity))\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run t-SNE for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize T-SNE\n",
    "tsne = TSNE(n_components=2, n_iter=7000, perplexity=40, random_state=42)\n",
    "\n",
    "# plot colors\n",
    "col_dict = matplotlib.colors.CSS4_COLORS\n",
    "c_out = ['mintcream', 'cornsilk', 'lavenderblush', 'aliceblue', 'antiquewhite', 'aqua', 'aquamarine', 'azure', 'beige', 'powderblue', 'floralwhite', 'ghostwhite',\n",
    " 'lightcoral', 'lightcyan', 'lightgoldenrodyellow', 'lightgray', 'lightgreen', 'lightgrey', 'lightpink', 'lightsalmon', 'lightseagreen', 'lightskyblue',\n",
    " 'lightslategray', 'lightslategrey', 'lightsteelblue', 'lightyellow', 'linen', 'palegoldenrod', 'palegreen', 'paleturquoise', 'palevioletred', 'papayawhip',\n",
    " 'peachpuff', 'mistyrose', 'lemonchiffon', 'lightblue', 'seashell', 'white', 'blanchedalmond', 'oldlace', 'moccasin', 'snow', 'darkgray',\n",
    " 'ivory']\n",
    "colormap = [c for c in col_dict if c not in c_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed: CNN - AE encoded vectors t-SNE\n"
     ]
    }
   ],
   "source": [
    "# t-SNE on the CNN encoded vectors\n",
    "# encoded = preprocessing.scale(encoded)\n",
    "encoded_tsne = tsne.fit_transform(encoded).tolist()\n",
    "print('Computed: CNN - AE encoded vectors t-SNE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE on the raw vectores\n",
    "# raw_tsne = tsne.fit_transform(raw_data_scaled).tolist()\n",
    "# print(\"Computed: raw count data t-SNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE on the TF-IDF + SVD matrix\n",
    "svd_mat = svd_tfidf(raw_data, len_vocab, n_dimensions = 100)\n",
    "tfidf_tsne = tsne.fit_transform(svd_mat).tolist()\n",
    "print(\"Computed: TF-IDF matrix t-SNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE on the LSTM encoded vectors\n",
    "# lstm_encoded_tsne = tsne.fit_transform(lstm_encoded_vect).tolist()\n",
    "# print(\"Computed LSTM encoded vectors t-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE visualization and external clustering validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the disease classes: first_disease, oth_disease\n",
    "disease_class_first = [gt_disease[m] for m in mrns]\n",
    "disease_dict = {d: i for i, d in enumerate(set(disease_class_first))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - AE encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "colors_en1 = [colormap[disease_dict[v]] for v in disease_class_first]\n",
    "single_plot(encoded_tsne, disease_class_first, colors_en1)\n",
    "\n",
    "# plot cluster results\n",
    "clusters = outer_clustering_analysis(encoded, disease_class_first)\n",
    "colors_en2 = [colormap[v] for v in clusters]\n",
    "single_plot(encoded_tsne, clusters, colors_en2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "# colors_raw1 = [colormap[disease_dict[v]] for v in disease_class_first]\n",
    "# single_plot(raw_tsne, disease_class_first, colors_raw1)\n",
    "\n",
    "# plot cluster results\n",
    "# clusters = outer_clustering_analysis(raw_data_scaled, gt_disease.values())\n",
    "# colors_raw2 = [colormap[v] for v in clusters]\n",
    "# single_plot(raw_tsne, clusters, colors_raw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "colors_tfidf1 = [colormap[disease_dict[v]] for v in disease_class_first]\n",
    "single_plot(tfidf_tsne, disease_class_first, colors_tfidf1)\n",
    "\n",
    "# plot cluster results\n",
    "clusters = outer_clustering_analysis(svd_mat, disease_class_first)\n",
    "colors_tfidf2 = [colormap[v] for v in clusters]\n",
    "single_plot(tfidf_tsne, clusters, colors_tfidf2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
