{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../outdir.txt', 'r')\n",
    "outdir = f.read().rstrip('\\n')\n",
    "f = open('../experiment_folder.txt', 'r')\n",
    "experiment_folder = f.read().rstrip('\\n')\n",
    "\n",
    "##Read encoded vectors file and ordered medical record numbers\n",
    "with open(experiment_folder + '/encoded_vect.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    encoded_vect = []\n",
    "    for r in rd:\n",
    "        encoded_vect.append(list(map(float, r)))       \n",
    "with open(experiment_folder + '/mrns.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    mrns = []\n",
    "    for r in rd:\n",
    "        mrns.append(r[0])\n",
    "\n",
    "# ##Read encoded vectors file and ordered medical record numbers\n",
    "# with open(experiment_folder + '/LSTMencoded_vect.csv') as f:\n",
    "#     rd = csv.reader(f)\n",
    "#     lstm_encoded_vect = []\n",
    "#     for r in rd:\n",
    "#         lstm_encoded_vect.append(list(map(float, r)))\n",
    "        \n",
    "# with open(experiment_folder + '/LSTMmrns.csv') as f:\n",
    "#     rd = csv.reader(f)\n",
    "#     lstm_mrns = []\n",
    "#     for r in rd:\n",
    "#         lstm_mrns.append(r[0])\n",
    "\n",
    "with open(outdir + '/cohort-new_ehr.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    raw_ehr = {}\n",
    "    for r in rd:\n",
    "        raw_ehr.setdefault(r[0], list()).extend(list(map(int, r[1::])))\n",
    "   \n",
    "##read the list of diseases associated to the mrns\n",
    "with open(outdir + '/cohort-mrn_diseases.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    mrn_disease = {}\n",
    "    for r in rd:\n",
    "        mrn_disease[r[0]] = r[1::]\n",
    "##create a list that orders the first diagnoses according \n",
    "##to the list of mrns\n",
    "mrn_encoded_disease = []\n",
    "for m in mrns:\n",
    "    mrn_encoded_disease.append(mrn_disease[m][0])\n",
    "\n",
    "#Vocabulary dictionary\n",
    "with open(outdir + '/cohort-new_vocab.csv') as f:\n",
    "    rd = csv.reader(f)\n",
    "    next(rd)\n",
    "    new_vocab = {}\n",
    "    for r in rd:\n",
    "        new_vocab[r[1]] = r[0]\n",
    "        \n",
    "len_vocab = len(new_vocab)\n",
    "\n",
    "with open(os.path.join(experiment_folder, \"subgroups.csv\"), 'r') as f:\n",
    "    rd = csv.reader(f)\n",
    "    models = next(rd) ##model labels \"cnn+ae\", \"lstm\", \"tfidf\", \"count\"\n",
    "    cluster = {}\n",
    "    for r in rd:\n",
    "        cluster.setdefault(r[0], list()).extend(r[1::])\n",
    "        \n",
    "with open(os.path.join(experiment_folder, \"svd_mat.csv\"), 'r') as f:\n",
    "    rd = csv.reader(f, delimiter=',')\n",
    "    svd_mat = [r for r in rd]\n",
    "    \n",
    "with open(os.path.join(experiment_folder, \"raw_data_scaled.csv\"), 'r') as f:\n",
    "    rd = csv.reader(f, delimiter=',')\n",
    "    raw_data_scaled = [ r for r in rd]\n",
    "    \n",
    "with open(os.path.join(experiment_folder, \"cluster.csv\"), 'r') as f:\n",
    "    rd = csv.reader(f, delimiter=',')\n",
    "    cluster.dict.fromkeys(next(rd))\n",
    "    tmp_mat = [r for r in rd]\n",
    "    tmp_mat = np.array(tmp_mat).T.tolist()\n",
    "    for m, v in zip(cluster, tmp_mat):\n",
    "        cluster[m] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity measure within diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disease_sim(model_mat, disease_vect, model):\n",
    "    for d in set(disease_vect):\n",
    "        tmp_mat = []\n",
    "        result = []\n",
    "        for idx, lab in disease_vect:\n",
    "            if lab == d:\n",
    "                tmp_mat.append(ehrs_mat[idx])\n",
    "        pair_sim = 1 - metrics.pairwise.euclidean_distance(tmp_mat)\n",
    "        mu = np.mean(pair_dist)\n",
    "        sd = np.sd(pair_dist)\n",
    "        string = \"Model {0} -- Disease {1}:: similarity ({2}, {3})\".format(model, d, mu, sd)\n",
    "        print(string)\n",
    "        result += string\n",
    "    f.open(os.path.join(experiment_folder, \"similarity_\" + model + \".txt\"), \"w\")\n",
    "    f.writelines([r for r in result])\n",
    "    f.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared test between new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_test(raw_ehr, vocab, new_classes, model):\n",
    "    count_mat = np.zeros(len_vocab, len(set(class_label)))\n",
    "    for c in set(class_label):\n",
    "        for idx, m in enumerate(mrns):\n",
    "            if class_label[idx] == c:\n",
    "                for tag in raw_data[mrn]:\n",
    "                    count_mat[tag][c] += 1\n",
    "    chi2_stat, p_val, dof, ex = stats.chi2_contingency(count_mat)\n",
    "    string = \"Chi-squared test statistics:\\\n",
    "              chi2_stat = {0} -- p_val = {1} -- dof = {2}\".format(chi2_stat,\n",
    "                                                                  p_val,\n",
    "                                                                  dof)#row = classes, columns = vocab\n",
    "    print(string)\n",
    "    f.open(os.path.join(experiment_folder), \"chi2_\" + model + \".txt\", \"w\")\n",
    "    f.write(string)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests on data\n",
    "\n",
    "#### CNN + AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"cnn+ae\"\n",
    "disease_vect = [mrn_disease[m][0] for m in mrns]\n",
    "disease_sim(encoded_vect, disease_vect, model)\n",
    "chi_test(raw_ehr, new_vocab, cluster[model], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"lstm\"\n",
    "disease_vect = [mrn_disease[m][0] for m in lstm_mrns]\n",
    "disease_sim(lstm_encoded_vect, disease_vect, model)\n",
    "chi_test(raw_eh, new_vocab, cluster[model], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"tfidf\"\n",
    "disease_vect = [mrn_disease[m][0] for m in raw_ehr]\n",
    "disease_sim(svd_mat, disease_vect, model)\n",
    "chi_test(raw_ehr, new_vocab, cluster[model], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"count\"\n",
    "disease_vect = [mrn_disease[m][0] for m in raw_ehr]\n",
    "disease_sim(raw_data_scaled, disease_vect, model)\n",
    "chi_test(raw_ehr, new_vocab, cluster[model], model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
