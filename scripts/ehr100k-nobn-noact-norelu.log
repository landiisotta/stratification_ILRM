[H[J
Vocabulary size: 31964
Cohort Size: 104735 -- Max Sequence Length: 32

Learning rate: 0.0001
Batch size: 16
Kernel size: 5

No. of GPUs: 1

Training for 10 epochs

Epoch 1 of 10
-- time =  9114.043
-- mean loss: 5.873
Epoch 2 of 10
-- time =  9111.521
-- mean loss: 5.473
Epoch 3 of 10
-- time =  9096.566
-- mean loss: 5.345
Epoch 4 of 10
-- time =  9073.838
-- mean loss: 5.276
Epoch 5 of 10
-- time =  9077.41
-- mean loss: 5.229
Epoch 6 of 10
-- time =  9075.098
-- mean loss: 5.2
Epoch 7 of 10
-- time =  9238.584
-- mean loss: 5.177
Epoch 8 of 10
-- time =  9361.268
-- mean loss: 5.162
Epoch 9 of 10
-- time =  9367.141
-- mean loss: 5.15
Epoch 10 of 10
-- time =  9360.697
-- mean loss: 5.14

Found new best model at epoch 10

Evaluating the model
Accuracy: 0.207 -- Loss: 5.187

Running clustering on the encoded vectors
Cluster: 0 -- Entropy: 1.227, Purity: 0.793
Cluster: 1 -- Entropy: 1.901, Purity: 0.550
Cluster: 2 -- Entropy: 1.337, Purity: 0.688
Cluster: 3 -- Entropy: 2.065, Purity: 0.362
Cluster: 4 -- Entropy: 1.865, Purity: 0.469
Cluster: 5 -- Entropy: 0.467, Purity: 0.932
Cluster: 6 -- Entropy: 0.894, Purity: 0.858
Average Entropy: 1.46
Average Purity: 0.66

Processing time: 97704.93 seconds

Task completed

