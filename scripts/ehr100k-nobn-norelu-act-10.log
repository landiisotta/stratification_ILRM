[H[J
Vocabulary size: 31964
Cohort Size: 104735 -- Max Sequence Length: 32

Learning rate: 0.0001
Batch size: 16
Kernel size: 5

No. of GPUs: 1

Training for 10 epochs

Epoch 1 of 10
-- time =  9091.055
-- mean loss: 7.694
Epoch 2 of 10
-- time =  9135.138
-- mean loss: 7.235
Epoch 3 of 10
-- time =  9138.954
-- mean loss: 7.012
Epoch 4 of 10
-- time =  9144.695
-- mean loss: 6.868
Epoch 5 of 10
-- time =  9122.567
-- mean loss: 6.76
Epoch 6 of 10
-- time =  9126.15
-- mean loss: 6.671
Epoch 7 of 10
-- time =  9117.383
-- mean loss: 6.602
Epoch 8 of 10
-- time =  9122.375
-- mean loss: 6.54
Epoch 9 of 10
-- time =  9119.163
-- mean loss: 6.487
Epoch 10 of 10
-- time =  9123.55
-- mean loss: 6.439

Found new best model at epoch 10

Evaluating the model
Accuracy: 0.205 -- Loss: 6.415

Running clustering on the encoded vectors
Cluster: 0 -- Entropy: 2.317, Purity: 0.289
Cluster: 1 -- Entropy: 1.684, Purity: 0.660
Cluster: 2 -- Entropy: 0.689, Purity: 0.898
Cluster: 3 -- Entropy: 2.122, Purity: 0.428
Cluster: 4 -- Entropy: 1.191, Purity: 0.801
Cluster: 5 -- Entropy: 1.466, Purity: 0.730
Cluster: 6 -- Entropy: 1.531, Purity: 0.681
Average Entropy: 1.52
Average Purity: 0.66

Processing time: 97556.71 seconds

Task completed

